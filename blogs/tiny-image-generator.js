const blog = {
    id: 1,
    title: 'Tiny Image Generator',
    date: '2025-12-10',
    excerpt: 'A KDE Based Image Generator for handwritten letters.',
    content: `# A TINY IMAGE GENERATOR
  I came across this youtube video ["I Built a Mini "GPT DALL-E" in One Day On a Laptop without GPU"](https://www.youtube.com/watch?v=2oh7Yp04cM8) from the channel CompuFlair. It was a very interesting video and approached the image generation problem through the perspective of a physicist. I went through the video and it was informative and interesting enough that it inspired me to try the concepts shared in the video myself. So, I started working on a small-scale handwritten letter generator.

  ### KDE and PCA
  KDE stands for [Kernel Density Estimator](https://en.wikipedia.org/wiki/Kernel_density_estimation).Kernel Density Estimation (KDE) is a method for approximating a random variable’s probability density function (PDF) using a finite sample.
  Using this, based on kernels, we can estimate the p.d.f of a random variable. Mathematically, given that $x = (x_1, x_2,  . . ., x_n)$ is a i.i.d samples from some univariate distribution of unknown density function, its Kernel Density Estimator is:
  $$
  \\hat{f}_h(x) = \\frac{1}{n}\\sum_{i=1}^{n}K_h(x - x_i)
  $$
  Where, $K_h$ is the scaled kernel, and $h$ is the bandwidth of the kernel.
  Intuitively, if n are the number of observations we have taken. Given the distribution of the observations, we want to estimate the overall distribution of the p.d.f the observations are taken from.
  Let us take some points from an unknown distribution
  ![](/blogs/images/tig/image.png?w=200px)
  As we keep on taking more samples, thy will roughly represent the unknown distribution. However through KDE, we can estimate the underlying distribution.
  ![](/blogs/images/tig/image-1.png?w=200px)
  The above function can be written as:
  $$
  \\hat{f}_h(x) = \\frac{1}{nh}\\sum_{i=1}^{n}K(\\frac{x - x_i}{h})
  $$
  The KDE is calculated by weighting the distances of all the data points we’ve observed. The more points nearby corresponds to the estimate being higher and hence a higher probability of that point.
  Selecting the bandwith is important, as we want it to be as lower as the data point allows us. This ensures that data points contribute strongly near themselves when the distance is nearly zero and weakly far away. A lower bandwidth means only close neighbors are taken while estimating, while a higher bandwidth means a larger neighborhood of points is considered. Choosing nearby points only may cause the estimate to look like this.
  ![](/blogs/images/tig/image-2.png?w=200px)

  Principal component analysis (PCA) is a linear dimensionality reduction technique with applications in exploratory data analysis, visualization and data preprocessing. The data are linearly transformed onto a new coordinate system such that the directions (principal components) capturing the largest variation in the data can be easily identified.

  In python, the scikit-learn library gives us methods for performing both KDE and PCA

  ### Implementation
  Diffusion models synthesize new images that are highly likely given the probability distribution. So knowing $P$, we can generate new images from it.
  Since images can be considered vectors, whose pixels are components of the vector. The probability distribution of an image can be estimated as:
  $$
  P(\\overrightarrow{x}) = \\frac{1}{nh}\\sum_{i=1}^{n}K(\\frac{x - x_i}{h})
  $$
  i.e. the sum over the images in the traiing set.

  But since the vector generated by images is very large, 28*28 in our case, KDE fails in this higher dimensional space. So we need to performa dimensionality reduction via PCA.
  The implementatin is below
  #### Imports

  ~~~
import numpy as np
from torchvision.datasets import EMNIST
from torchvision import transforms

from sklearn.decomposition import PCA
from sklearn.neighbors import KernelDensity
from PIL import Image
  ~~~

  #### Dataloader

  ~~~
  def get_emnist_data(split: str = "train", emnist_split: str = "letters"):
    """
    Returns EMNIST data as float32 array in shape (N, 784) normalized to [0, 1].
    """
    transform = transforms.Compose([
      transforms.ToTensor(),
      transforms.Lambda(lambda x: x.transpose(1, 2))  #fixing rotation
    ])

    dataset = EMNIST(
        root="./data",
        split=emnist_split,
        train=(split == "train"),
        download=True,
        transform=transform
    )

    X = []
    y = []

    for img, label in dataset:
        X.append(img.reshape(-1).numpy().astype(np.float32))  
        y.append(int(label))

    X = np.stack(X)
    y = np.array(y, dtype=int)

    return X, y
  train_data = get_emnist_data()
~~~

#### View the data
~~~
    def show_examples(X, y, num=10):
      """
      X: (N, 784) float32 images
      y: (N,) integer labels
      num: number of samples to show
      """
      plt.figure(figsize=(12, 2))

      for i in range(num):
          ax = plt.subplot(1, num, i + 1)
          img = X[i].reshape(28, 28)

          plt.imshow(img, cmap="gray")
          plt.title(str(y[i]))
          plt.axis("off")

      plt.tight_layout()
      plt.show()
    show_examples(train_data[0], train_data[1])
~~~
![](/blogs/images/tig/ig_ex.png)
~~~
  def fit_pca_kde(X: np.ndarray, n_components: int, bandwidth: float, kernel: str = "gaussian"):
	"""
	Fit PCA to reduce dimensionality, then fit KDE in PCA space.
	Returns fitted PCA and KDE models.
	"""
	pca = PCA(n_components=n_components, random_state=42)
	Z = pca.fit_transform(X)
	Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float64)

	kde = KernelDensity(kernel=kernel, bandwidth=bandwidth)
	kde.fit(Z)
	return pca, kde


def sample_images_improved(pca: PCA, kde: KernelDensity, Z_train: np.ndarray,
                           n_samples: int) -> np.ndarray:
    """
    Sample from KDE using importance resampling from training data.
    """
    rng = np.random.default_rng()

    n_train = len(Z_train)

    bandwidth_scale = 0.5  
    samples_Z = []

    for _ in range(n_samples):

        idx = rng.integers(0, n_train)
        z_base = Z_train[idx]

        noise = rng.normal(0, bandwidth_scale, size=z_base.shape)
        z_sample = z_base + noise
        samples_Z.append(z_sample)

    Z = np.array(samples_Z)

    X_gen = pca.inverse_transform(Z)
    X_gen = np.clip(X_gen, 0.0, 1.0)

    return X_gen


def save_images(X: np.ndarray, out_dir: Path, prefix: str = "sample", out_size: int | None = None):
	out_dir.mkdir(parents=True, exist_ok=True)
	for i, x in enumerate(X):
		img_arr = (x.reshape(28, 28) * 255.0).astype(np.uint8)
		img = Image.fromarray(img_arr, mode="L")
		if out_size and out_size > 28:
			img = img.resize((out_size, out_size), resample=Image.LANCZOS)
		img.save(out_dir / f"{prefix}_{i:04d}.png")


def fit_pca_kde_per_letter(X: np.ndarray, y: np.ndarray, n_components: int = 50,
                           bandwidth: float = 1.0, kernel: str = "gaussian"):
    """
    Fit separate PCA+KDE models for each letter class.
    Returns dict of {letter_label: (pca, kde, Z_train)}.
    """
    models = {}
    unique_letters = np.unique(y)

    for letter in unique_letters:
        X_letter = X[y == letter]

        if len(X_letter) < n_components:
            print(f"Warning: Letter {letter} has only {len(X_letter)} samples, skipping...")
            continue

        pca = PCA(n_components=n_components, whiten=True, random_state=42)
        Z = pca.fit_transform(X_letter)

        kde = KernelDensity(kernel=kernel, bandwidth=bandwidth)
        kde.fit(Z)

        models[letter] = (pca, kde, Z)

    return models

def sample_letter(models: dict, letter_label: int, n_samples: int) -> np.ndarray:
    """Sample n_samples of a specific letter."""
    if letter_label not in models:
        raise ValueError(f"Letter {letter_label} not found in models")

    pca, kde, Z_train = models[letter_label]
    return sample_images_improved(pca, kde, Z_train, n_samples)
  ~~~
#### Running everything
  ~~~
X = train_data[0]  
y = train_data[1]  

X = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=0.0).astype(np.float32)
if X.size == 0:
    raise ValueError("No samples found.")

n_components = 50
bandwidth = 0.5
kernel = "gaussian"
n_samples_per_letter = 5  
out_size = 112
out_dir = "."

print("Training PCA+KDE models for each letter...")
models = fit_pca_kde_per_letter(X, y, n_components, bandwidth, kernel)

print("Generating samples...")
all_samples = []
unique_letters = sorted(np.unique(y)) 

for letter_label in unique_letters:
    print(f"  Sampling letter {letter_label}...")
    samples = sample_letter(models, letter_label, n_samples_per_letter)
    all_samples.append(samples)

X_gen = np.vstack(all_samples)

out_dir = Path(out_dir) / "samples_letters"
save_images(X_gen, out_dir, out_size=out_size)
print(f"Saved {len(X_gen)} images to {out_dir}")
~~~
#### Results
![](/blogs/images/tig/a.png?w=200px) ![](/blogs/images/tig/f.png?w=200px)

#### References
[Kernel Density Estimator](https://en.wikipedia.org/wiki/Kernel_density_estimation) 

[Visualizer](https://mathisonian.github.io/kde/)
  `

  };
  
  export default blog;